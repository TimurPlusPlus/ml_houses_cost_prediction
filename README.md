# ml_houses_cost_prediction

1) Loading the Boston dataset.  
2) Exploratory analysis such as checking the number of examples, the number of features, the histogram of outputs. Identify your problem. Is it regression or classification?  
3) Coming up with a dumb baseline and choosing the metrics to use. We have discussed these choices during our classes.  
4) Splitting your dataset into train/dev/test samples (80%/10%/10% should be fine) as we discussed during our classes.
5) Training your XGBoost model using different values of hyperparameters and finding the best set of hyperparameters. Explain your choice of parameters and their possible values in a text section before the code.  
6) Validating your results on the test sample and coming up with some conclusion. Was there overfitting/underfitting? How does it compare to the baseline? Explain what you observe in a few sentences in a text section.  
  
The notebook should be reproducible. This means anyone should be able to run it and get the same results. Set the random seeds for all random operations. If I wouldn't be able to run your notebook it would be an issue you'd have to resolve.  
